{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542ade4d-9208-4b5c-aa01-51b502d50ab8",
   "metadata": {},
   "source": [
    "# Open Data Hub + Starburst Enterprise Platform:  <br>  Access and Explore your Data\n",
    "\n",
    "## Introduction\n",
    "**Open Data Hub**, a platform for data scientists and developers of intelligent applications, supports the full Machine Learning lifecycle by providing a robust, scalable platform and a flexible, interactive environment for teams to do their work. \n",
    "\n",
    "**Starburst Enterprise Platform** (formerly PrestoSQL) provides a secure and performant single point of access to all of your data without having to first copy or move it to a central repository. Starburst Enterprise Platform focuses on the first, and often most difficult problem teams face when starting a new project -- the acquisition and preparation of data. With Starburst Enterprise Platform, data scientists and developers will be able to quickly and easily combine data from multiple sources to perform comprehensive analyses for their organizations.\n",
    "\n",
    "This demonstration illustrates how quickly a data scientist can access data and pull it into the Open Data Hub Jupyter environment using Starburst Enterprise Platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc700d-18bb-4584-b8dc-a9b5fff21430",
   "metadata": {},
   "source": [
    "## Installing Required Packages\n",
    "Open Data Hub provides images loaded with popular open source data science packages. These are also the notebook images we use when building our own intelligent applications. \n",
    "\n",
    "While these images typically have everything we need, we can always layer in specific package requirements using `pip` and a `requirements.txt` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917fa02-3309-4e0f-bbe3-fb54cb045cde",
   "metadata": {},
   "source": [
    "## Environment Initialization\n",
    "\n",
    "### Import packages and environment variables\n",
    "Let's import the package we installed in the previous step and assign environment variables we included while spawning our notebook. This way, we won't accidentally expose sensitive connection information!\n",
    "\n",
    "Lastly, we use these variables and the `trino.dbapi.connect` function to create our Connection object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6830c-e694-498d-bbd9-f5e72c3b5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "import trino\n",
    "\n",
    "\n",
    "TRINO_USERNAME = os.environ.get('TRINO_USERNAME', 'trino')\n",
    "TRINO_PASSWORD = os.environ.get('TRINO_PASSWORD', 'trino')\n",
    "TRINO_HOSTNAME = os.environ.get('TRINO_HOSTNAME', 'CHANGE_ME')\n",
    "TRINO_PORT = os.environ.get('TRINO_PORT', '80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65788218-cd50-4689-8bf6-8bba06607aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = trino.dbapi.connect(\n",
    "    host=TRINO_HOSTNAME,\n",
    "    port=TRINO_PORT,\n",
    "    user=TRINO_USERNAME,\n",
    "    http_scheme='http',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd69176-0a9a-4e4f-b654-1ff330efb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(sql, connector):\n",
    "    \"\"\"Return pandas DataFrame.\"\"\"\n",
    "    \n",
    "    cur = connector.cursor()\n",
    "    cur.execute(sql)\n",
    "    response = pandas.DataFrame(\n",
    "        cur.fetchall(), columns=[c[0] for c in cur.description]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c48f7-7510-4fd6-a5db-2754d21fa2ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is Starburst Enterprise Platform and how does it work? \n",
    "Starburst Enterprise Platform is an incredibly efficient layer sitting between the data consumer and our data sources. It brings our data together so we can query sources individually or join them together in ways that previously required extensive ETL processes.\n",
    "\n",
    "Let's use our connection object and SQL statements to interact with Starburst Enterprise Platform. \n",
    "\n",
    "The following SQL statements help us understand our data sources:\n",
    "* `'SHOW CATALOGS'` shows the data sources available to us at this time,\n",
    "* `'SHOW SCHEMAS'` indicates how data tables are organized, and \n",
    "* `'SHOW TABLES'` exposes datasets within a catalog and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04fdaa-1a32-4f11-b70b-86e7c42c1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW CATALOGS'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c124cd-17a6-4c22-81cb-cc7dc5cbaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW SCHEMAS from s3'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f52505-2b3c-4b12-9816-0740ab14bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW TABLES FROM s3.tpch'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550abbd7-7adb-4729-aba3-57f8645a4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'DESCRIBE s3.tpch.customer'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927aedfc-5055-4fcd-9540-c3991255c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM s3.tpch.customer limit 40'\n",
    "df = get_sql(sql, conn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6988a2-5c67-4660-894b-f770b1a6cdbe",
   "metadata": {},
   "source": [
    "**Please note**:\n",
    "Your data sources will show up under `'SHOW CATALOGS'` after their respective connectors are configured in your catalog.\n",
    "\n",
    "**Some useful terminology**:\n",
    "* **data source** - your data stored in a database, bucket, or other. Starburst Enterprise Platform has connectors for most sources already. \n",
    "* **connector** - connectors configure your catalog. They give you access to your data sources. They are similar to drivers, in a way.\n",
    "* **catalog** - defines schemas and properties of connections so Starburst Enterprise Platform knows how to query your data.\n",
    "* **schema**  - how your tables are organized.\n",
    "* **table**   - similar to tables in a relational database. A set of rows and columns representing your data based on connector properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb982c0-c31e-401d-92ec-ee94328f2aa8",
   "metadata": {},
   "source": [
    "## Accessing Data\n",
    "We've seen the data sources we have access to (CATALOGS), their associated SCHEMAS, and some data tables from tpch.  Let's run some actual queries to access the data!\n",
    "\n",
    "For the following example, we'll assume there are CSV files in an S3 bucket \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a92a9b-44cd-483d-9b0c-bc294ae802d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = \"CREATE SCHEMA s3.test WITH (location = 's3a://test/')\"\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee271c4a-09c7-4b9d-b921-c3c97948cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "CREATE TABLE s3.test.customers ( \n",
    "   customer_id BIGINT, \n",
    "   label TINYINT\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf9f3b-b6fb-4a1a-af9c-7a0dbb4a6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "INSERT INTO s3.test.customers VALUES (43, 1)\n",
    "\n",
    "\"\"\"\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6ae7d-347e-47f4-8c94-ca4cc948c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW TABLES FROM s3.test'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f49bcd-c16a-434c-ba5d-268cf99fc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'DESCRIBE s3.test.customers'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c1b40-e4a5-4473-8fbd-029a495695f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM s3.test.customers limit 40'\n",
    "df = get_sql(sql, conn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5102a-4039-449b-a208-b5301ba3a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'DROP TABLE s3.test.customers'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415c871-7e06-485e-b781-b25034cff3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'DROP SCHEMA s3.test'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092145de-8401-47a6-8d85-e3ebcbb6bb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dependency_resolution_engine": "pipenv",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "requirements": "{\"packages\":{\"trino\":\"*\",\"boto3\":\"*\"},\"requires\":{\"python_version\":\"3.8\"},\"source\":[{\"name\":\"pypi\",\"url\":\"https://pypi.org/simple\",\"verify_ssl\":true}]}",
  "requirements_lock": "{\"_meta\":{\"sources\":[{\"url\":\"https://pypi.org/simple\",\"verify_ssl\":true,\"name\":\"pypi\"}],\"requires\":{\"python_version\":\"3.8\"},\"hash\":{\"sha256\":\"6e80728e57562982efed6a2842155743c7fed9d663e0d8a1b29a9a1a820901a1\"},\"pipfile-spec\":6},\"default\":{\"boto3\":{\"version\":\"==1.24.48\",\"hashes\":[\"sha256:632676a480854d7c18ae634e2e83a93dc27211b88e19340e047bbd432128819e\",\"sha256:db27c33a7ccccbf76035ab47e92054ce8ab98b809cf49eb15a2502eedc3ba332\"],\"index\":\"pypi\"},\"botocore\":{\"version\":\"==1.27.48\",\"hashes\":[\"sha256:5958ef6dd3b0f84eb1ee0aac75499ac504fcc0787fd6611be727968d51dcbfa7\",\"sha256:8de2f4285046ed306439723a11706067d6901c3f7be418b7b104ba8e002b5638\"],\"markers\":\"python_version >= '3.7'\"},\"certifi\":{\"version\":\"==2022.6.15\",\"hashes\":[\"sha256:84c85a9078b11105f04f3036a9482ae10e4621616db313fe045dd24743a0820d\",\"sha256:fe86415d55e84719d75f8b69414f6438ac3547d2078ab91b67e779ef69378412\"],\"markers\":\"python_full_version >= '3.6.0'\"},\"charset-normalizer\":{\"version\":\"==2.1.0\",\"hashes\":[\"sha256:5189b6f22b01957427f35b6a08d9a0bc45b46d3788ef5a92e978433c7a35f8a5\",\"sha256:575e708016ff3a5e3681541cb9d79312c416835686d054a23accb873b254f413\"],\"markers\":\"python_full_version >= '3.6.0'\"},\"idna\":{\"version\":\"==3.3\",\"hashes\":[\"sha256:84d9dd047ffa80596e0f246e2eab0b391788b0503584e8945f2368256d2735ff\",\"sha256:9d643ff0a55b762d5cdb124b8eaa99c66322e2157b69160bc32796e824360e6d\"],\"markers\":\"python_version >= '3.5'\"},\"jmespath\":{\"version\":\"==1.0.1\",\"hashes\":[\"sha256:02e2e4cc71b5bcab88332eebf907519190dd9e6e82107fa7f83b1003a6252980\",\"sha256:90261b206d6defd58fdd5e85f478bf633a2901798906be2ad389150c5c60edbe\"],\"markers\":\"python_version >= '3.7'\"},\"python-dateutil\":{\"version\":\"==2.8.2\",\"hashes\":[\"sha256:0123cacc1627ae19ddf3c27a5de5bd67ee4586fbdd6440d9748f8abb483d3e86\",\"sha256:961d03dc3453ebbc59dbdea9e4e11c5651520a876d0f4db161e8674aae935da9\"],\"markers\":\"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'\"},\"pytz\":{\"version\":\"==2022.1\",\"hashes\":[\"sha256:1e760e2fe6a8163bc0b3d9a19c4f84342afa0a2affebfaa84b01b978a02ecaa7\",\"sha256:e68985985296d9a66a881eb3193b0906246245294a881e7c8afe623866ac6a5c\"]},\"requests\":{\"version\":\"==2.28.1\",\"hashes\":[\"sha256:7c5599b102feddaa661c826c56ab4fee28bfd17f5abca1ebbe3e7f19d7c97983\",\"sha256:8fefa2a1a1365bf5520aac41836fbee479da67864514bdb821f31ce07ce65349\"],\"markers\":\"python_version >= '3.7' and python_version < '4'\"},\"s3transfer\":{\"version\":\"==0.6.0\",\"hashes\":[\"sha256:06176b74f3a15f61f1b4f25a1fc29a4429040b7647133a463da8fa5bd28d5ecd\",\"sha256:2ed07d3866f523cc561bf4a00fc5535827981b117dd7876f036b0c1aca42c947\"],\"markers\":\"python_version >= '3.7'\"},\"six\":{\"version\":\"==1.16.0\",\"hashes\":[\"sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926\",\"sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\"],\"markers\":\"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'\"},\"trino\":{\"version\":\"==0.315.0\",\"hashes\":[\"sha256:a48baaf327718e60aa4b208a32469ecde068b100c1c4027690a583497dd9a5c8\",\"sha256:b10f40e9d178602b39463adb57c207a6c1803eb1a8ecb8cc9d5e710cf3dfbbc7\"],\"index\":\"pypi\"},\"urllib3\":{\"version\":\"==1.26.11\",\"hashes\":[\"sha256:c33ccba33c819596124764c23a97d25f32b28433ba0dedeb77d873a38722c9bc\",\"sha256:ea6e8fb210b19d950fab93b60c9009226c63a28808bc8386e05301e25883ac0a\"],\"markers\":\"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3, 3.4, 3.5' and python_version < '4'\"}},\"develop\":{}}"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
