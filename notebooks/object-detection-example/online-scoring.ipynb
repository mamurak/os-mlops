{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c06e224-7916-4b95-ab14-37ebd2e2b761",
   "metadata": {},
   "source": [
    "# Testing the Model Deployment\n",
    "\n",
    "After deploying the model using RHODS Model Serving, we'd like to test the model deployment by sending images to the model server for real-time inference.\n",
    "\n",
    "In this notebook we'll review how to consume the model through the RHODS Model Server.\n",
    "\n",
    "We'll start by importing the preprocessing and rendering functions that we have worked with in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48db30-205c-4458-8f84-2e55599db6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from requests import post\n",
    "import torch\n",
    "\n",
    "from classes import classes\n",
    "from preprocessing import preprocess_image_file\n",
    "from object_detection import postprocess\n",
    "from object_rendering import draw_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88027c49-fbe2-4a72-ac46-266ab0becbb6",
   "metadata": {},
   "source": [
    "Let's prepare one of our sample images as a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c78714-460e-40c7-b47d-2685f4b668b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'sample-images/street.jpg'\n",
    "transformed_image, scaling, padding = preprocess_image_file(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23911b76-1bd3-45ac-8a80-8d2d97c1ab9c",
   "metadata": {},
   "source": [
    "For testing the model deployment, our test script needs to know the address of the model server. Let's insert the **inference endpoint** that the RHODS Dashboard provides for the deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffad01-a4cc-4d96-b725-309655636768",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_url = 'REPLACE_ME'\n",
    "token = 'REPLACE_ME'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb9cf-48c6-438c-a776-e06d013dcd0c",
   "metadata": {},
   "source": [
    "We'll now need to package the preprocessed image into a format that the model server can consume. RHODS Model Serving implements a generic prediction interface that allows to query the typical model formats through the HTTP POST method using a JSON request body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdc026-6119-4749-ab98-44d1828e64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(image):\n",
    "    payload = {\n",
    "        'inputs': [\n",
    "            {\n",
    "                'name': 'images',\n",
    "                'shape': [1, 3, 640, 640],\n",
    "                'datatype': 'FP32',\n",
    "                'data': image.flatten().tolist(),\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a32e3-5202-480c-bac7-3a12706ca963",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = serialize(transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d859e1-f9d1-4801-be38-8db71cf8e31e",
   "metadata": {},
   "source": [
    "Let's now send the serialized cat image to the model server. The inference results will also be returned in a generic JSON structure, which we can unpack straightaway. We'll also apply the post-processing function we defined in the previous notebook to extract the familiar object properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3eb6c3-43d0-4fbb-a830-286c118218fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_response(payload, prediction_url, classes_count, token=''):\n",
    "    headers = {'Authorization': f'Bearer {token}'} if token else {}\n",
    "    raw_response = post(prediction_url, json=payload, headers=headers)\n",
    "    try:\n",
    "        response = raw_response.json()\n",
    "    except:\n",
    "        print(f'Failed to deserialize service response.\\n'\n",
    "              f'Status code: {raw_response.status_code}\\n'\n",
    "              f'Response body: {raw_response.text}')\n",
    "    try:\n",
    "        model_output = response['outputs']\n",
    "    except:\n",
    "        print(f'Failed to extract model output from service response.\\n'\n",
    "              f'Service response: {response}')\n",
    "    unpacked_output = _unpack(model_output, classes_count)\n",
    "    return unpacked_output\n",
    "\n",
    "\n",
    "def _unpack(model_output, classes_count):\n",
    "    arr = np.array(model_output[0]['data'])\n",
    "    # Get the response data as a NumPy Array\n",
    "\n",
    "    output = torch.tensor(arr)  # Create a tensor from array\n",
    "    prediction_columns_number = 5 + classes_count\n",
    "    # Model returns model returns [xywh, conf, class0, class1, ...]\n",
    "\n",
    "    output = output.reshape(\n",
    "        1,\n",
    "        int(int(output.shape[0])/prediction_columns_number),\n",
    "        prediction_columns_number\n",
    "    )  # Reshape the flat array prediction\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66568dae-81cd-41cd-80fd-645c39a08755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = classes['coco']\n",
    "raw_objects = get_model_response(payload, prediction_url, len(class_labels), token=token)\n",
    "objects = postprocess(raw_objects)\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4baed58-595b-49ff-86ed-c9921368a1a8",
   "metadata": {},
   "source": [
    "Let's now visualize the result as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96301c5-5198-420e-9ab6-3efd9e8e844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(image_path, objects, scaling, padding, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c64ff-f6d2-4bfa-8417-2885c0b94ee7",
   "metadata": {},
   "source": [
    "We were able to reproduce the object detection example from the previous notebook, so we can consume the deployed model as expected.\n",
    "\n",
    "You can now head over to deploying the object detection application to consume this model in a real-time fashion.\n",
    "\n",
    "After that, we'll explore offline scoring in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495133a-2f62-4c9e-8071-df0c3135a50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
